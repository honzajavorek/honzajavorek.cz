Title: Empowered by AI: Why junior devs have the winning edge
Image: images/woman-programming-on-her-laptop.jpg
Lang: en
Tags: highlight
Status: draft

I'm in the business of [helping people to switch careers and learn coding](https://junior.guru/).
There is a lot of fear, uncertainty and doubt about whether AI replaces software engineers altogether or at least makes it harder for junior programmers to start in the field.
Some people think that companies won't have any reason to offer entry level positions.
I think quite the opposite!
Junior devs have the winning edge.

![Empowered by AI: Why junior devs have the winning edge]({static}/images/woman-programming-on-her-laptop.jpg)
I found her on [Lexica.art](https://lexica.art/prompt/9be96fa9-4d86-40c7-bcb9-2ef287062032)

Hype aside, here are some facts:
AI suddenly makes many unscalable tasks scale and many impossible tasks possible.
[Unlike blockchain](https://blog.mollywhite.net/is-web3-bullshit/) and other recent hypes, people immediately see value in what the tool provides.
Using the tools is free or reasonably cheap.
Everyone easily comes up with tasks where it can help.
And when I say everyone, I mean even your hairdresser.
I think this is a game-changer, similar to a calculator, car, personal computer, or a smartphone.

## How smartphone augments my abilities

Let's take a closer look at how the latest of these inventions changed our lives.
When I get lost in streets and I look at my iPhone, I can immediately see exactly where I am.
I can look up the closest ATMs.
I can walk to one of them and use contactless Apple Pay to withdraw some cash.
And that is just a fraction of what the phone can do.
It augments my abilities in such a way that in his 30s, my grandfather would think it's all just pure sorcery.

At any place, at any moment, I have easy access to most of the information collected by humans, in all its breadth and depth.
My grandfather had a limited set of books, maybe a radio.
I have internet, Google, Wikipedia.

![Kniha Lidé a informace]({static}/images/img-2861.jpg)
Book [People and information](https://www.databazeknih.cz/knihy/lide-a-informace-146195) by Vladimír Smetáček, 1981, photo by me

I'm also way more ambitious with what I work on.
With all the parallel conversations, tasks, and projects, I'm probably 100 times more effective and productive than my granddad.
I don't say this is only good, fetishizing productivity and trying to get done more in every second of our lives [has its own problems](https://www.oliverburkeman.com/posts), but the fact is that thanks to technology advancements augmenting my abilities, I _can_ do more than my ancestors.

My smartphone or personal computer also compensate my limitations.
I'm so bad at math that I can't do 12 + 42 in my head without embarrassing amount of effort.
So I type even simple stuff like that to the calculator (to be precise, to the Spotlight or Google search fields).
I might feel silly doing it, but at the same time, I know I can rely on it.
Anytime.
Thanks to that, I'm not afraid of adding.
Not even multiplying!
And with [WolframAlpha](https://www.wolframalpha.com/), I'm downright invincible.

## AI stands for 'new cool tool'

Now back to AI.
Today the two letters are used almost interchangably with ChatGPT etc., but it's good to know what AI actually means.
Basically, every time humans invent something that allows computer to do stuff which it couldn't do before, we call it artificial intelligence.
Since the beginning of computers, AI plays against us in single-player games.
It detects faces so that our cameras could take better pictures.
It's behind the translations in Google Translate or spell check in Google Docs.
Those are just a few examples, but really, it's already everywhere around us.
When we get used to it, the AI label moves to something newer, which is more _wow_.

![0 A.D. screenshot]({static}/images/screenshot-2023-04-15-at-22-15-20.png)
AI in my favorite computer game, [0 A.D.](https://play0ad.com/)

Simon Willison says [LLMs like GPT are calculators for words](https://simonwillison.net/2023/Apr/2/calculator-for-words/).
I think this analogy is useful also for predictions about future.
We'll learn how to use these calculators, then we'll adapt, get bored, and we'll move on.

The first iPhone has been released in 2007, when I was 20.
While smartphones changed many aspects of my life and in the eyes of my ancestors I now possess unthinkable superpowers, today the device is not _wow_, it's boring.

With my tasks and projects, I naturally moved to a higher level of abstraction.
To find something, my granddad had to have a physical map, he had to know how to locate himself on the map, and he had to understand many details about how maps work.
Today, I can type "kebab" to Google Maps, tap on an arrow, and then voice tells me where to go.
I can focus on the task and forget the details.

## LLMs are the next level of augmentation

Some people say LLMs (large language models) make mistakes and that's why they're downright _useless_.
But in this world, nothing is perfect.
Humans are okay doing some extra steps if there's a tool just _good enough_.
If it solves [80 % of the problem with 20 % of the effort](https://en.wikipedia.org/wiki/Pareto_principle), great!
This is true for cars, phones, planes, computers, all software, and it's gonna be true for LLMs, too.

In just a few months after the ChatGPT launch, we now have [GPT-4](https://openai.com/research/gpt-4), which is much better, and [plugins](https://openai.com/blog/chatgpt-plugins), which change the game further.
Still, as of now, asking ChatGPT to return facts or other exact stuff isn't the best way to use it.
However, it is already an amazing tool for mentoring, learning, brainstorming.

> Instead of blindly copy/pasting the code that ChatGPT generates, go through it line-by-line, and make sure you understand. Ask it for clarification. And double-check things that seem suspicious with an authoritative source (eg. the official documentation). Keep in mind that LLMs are 100% confident, but not 100% accurate.
>
> — Josh Comeau, [The End of Front-End Development](https://www.joshwcomeau.com/blog/the-end-of-frontend-development/)

See how last December, Simon Willison [used ChatGPT and GitHub Copilot to learn Rust](https://simonwillison.net/2022/Dec/5/rust-chatgpt-copilot/).
I've seen people telling the LLM to behave like a tutor who never answers directly, but guides you to come up with the solution yourself by giving you questions and little hints.
This can be further enhanced with [links to relevant docs and additional explanations](https://www.youtube.com/watch?v=91IPJ6LFmto).
Despite its imperfections, it's already very, very useful!

## Junior stands for 'less experience'

Some say that ChatGPT or GitHub Copilot produces code which is already similar to what an entry level software engineer would write.
They conclude that this means junior devs won't be needed anymore.

First of all, being a junior is just a career phase.
People try something, get better, become juniors, get better, become seniors.
Tools can make the transition easier or faster, but they cannot replace juniors specifically.

As far as I know, AI can't clone people yet.
Although I've seen many companies neglecting the truth and spending immense money and resources on hiring seniors instead of raising juniors, the only way seniors can really reproduce is by teaching those who are less experienced.

I feel a bit silly that I must explicitly state something so obvious, but there are no seniors without juniors.
Juniors are future seniors and all seniors are past juniors.

As I've described, AI already makes the transition from junior to senior faster and easier.
However, it cannot completely erase the difference between people with experience and without experience doing the job.
If there's no such difference, it means the job is not needed at all.
And I don't think AI will make all devs redundant (more on that later).

## Why junior devs have the best timing

If there is a new tool augmenting our abilities and learning is suddenly faster and easier, what's the outcome?
Better juniors and seniors!

![Chart]({static}/images/juniors.svg)

This is a bit silly chart, but you probably get how I think about it.
It's gonna be the same as with personal computers.
The accountants still exist, they just transformed into _personal computer operators_.
The architects still exist.

![Design]({static}/images/screenshot-2023-04-15-at-15-52-25.png)

Do you see the lines, numbers, and letters?
The architects used to [draw all this manually](https://en.wikipedia.org/wiki/Architectural_drawing).
Today they have AutoCADs.
The emergence of software for architects didn't mean junior architects now don't exist.
They moved to a different level of abstraction with their work.
They can skip technicalities and focus on the task at hand.
And perhaps the teams can now be more ambitious and build something crazier, such as [organic architecture](https://en.wikipedia.org/wiki/Organic_architecture), which isn't just straight lines and right angles.

The AI will cause a revolution.
It will shake the job market, but not in a way that junior devs would be unneccessary.
Gradually or suddenly, depending on how fast this all goes, companies will start preferring people who are fluent with the new AI superpowers.
The same way they, back then, started to prefer people who could have augment their job with MS Word 97 and we've seen "computer skills" highlighted in peoples' CVs or taught in schools.

Those who were just learning accounting or architecture at that time had the best timing.
During their studies, they had to write everything on paper, which must have been annoying if they already had a hunch that computers could do it for them, but in their careers, they were the first personal computer operators in their field.
And the people whose careers were already in progress?
They had to learn computers and adapt to the new normal.

The smarter ones among beginners already use AI as their mentor.
They won't need to change their habits, routines, tools, approach.
They won't need to let go their perfectionism and love for carefully crafting every single line of code, because they already start with suspiciously scanning through larger chunks of suggested code.
They won't need to learn how to prompt ChatGPT or GitHub Copilot.
For them, it will be natural.
Soon, some juniors skilled in augmenting their capabilities with AI might be actually preferred over seniors who don't get used to work with these new tools.

This is true revolution.
The old class system collapses, a [new one is about to be established](https://youtu.be/EdddrKJgUJg?t=630).
Those who can quickly learn how to use these things will benefit from the shake up and get nice careers or become respected authorities.
Those who stick to their old ways will be pushed aside.

You think it's not about you, right?
It's about that old fart daily commuting to a cubicle in a big office building, [working on some Java 8 systems](https://vickiboykis.com/2019/05/10/it-runs-on-java-8/).
But no, all seniors are inflexible.
Python 3.5, which introduced [type hints](https://peps.python.org/pep-0484/), has been released in 2015.
First time I tried using them in my project?
Few weeks ago.
It took me 8 years to just _try_ them.

I'm not afraid AI will replace juniors.
I'm afraid juniors augmented by AI will replace us seniors.

## Closing the university gap

I already mentioned I help people to learn coding and find their first job as a dev.
While I'm happy to support computer studies graduates in their efforts, I mainly focus on those who come to switch their career from a different job.

The usual way they do the switch is that they bet on one of the most demanded programming ecosystems (currently frontend or Python), then they laser focus on learning, and as soon as they're able to produce useful code, they apply for entry level jobs.
But even though they become vital members of engineering teams, as they progress in their careers, they realize they're still lacking some knowledge compared to those who studied computers at university.

Everyday React components?
Sure, no problem.
But then some tasks require deeper knowledge of operating systems, algorithms, databases, perhaps even compilers…
In such cases, the career switcher either attempts to reinvent the wheel, or admits they don't know how to approach the problem and ask for guidance.

No matter how well university graduates prepared for the exams, they have been through many subjects and seen many concepts.
They don't remember most of the details, but they know they exist.
They have a hunch certain problems have already invented solutions with certain names.
Maybe they don't remember it exactly, but Google helps.
They tap on an old memory, search for "philosophers fork algorithm", get the Wikipedia page for the [Dining philosophers problem](https://en.wikipedia.org/wiki/Dining_philosophers_problem), read solutions.
They have general overview of the field and they know what they don't know.

> Students will understand all the layers of the computer based systems including hardware (semiconductor components, logic networks, processors, peripheral devices), software (control and data structures, object orientation, programming languages, compilers, operating systems, databases), as well as their common applications (information systems, computer networks, artificial intelligence, computer graphics and multimedia). They will understand foundations of computer science (discrete mathematics, formal languages and their models, spectral analysis of signals, modelling and simulation). Graduates will be able to analyse, design, implement, test, and maintain common computer applications. They will be able to work efficiently in teams.
>
> — [Degree Programme Details](https://www.fit.vut.cz/study/program/7886/.en), Faculty of Information Technology, Brno University of Technology

The issue with career switchers is that they don't know what they don't know.
This means they don't know what to look for.
What to ask about.

I think this is essentially a problem of discoverability of information.
We used to have schools trying to provide us with general overview by memorizing facts.
Now we have schools which are more relaxed, but still require us to have the basic fact grid memorized.
The data points we remember give us some guidance while we can fill the gaps [just-in-time](https://en.wikipedia.org/wiki/Lean_manufacturing) using the internet.

So we have Google and Wikipedia, but when we're solving tasks, we still need to know what to search for in order to have our abilities augmented by the existing knowledge on the topic.
One can do their own research, but that's a tedious task, because without good materials it's hard to recognize what is noise and what is signal.

Let's say I want to solve efficiently displaying billions of pins on a [Leaflet](https://leafletjs.com/) map.
Basic tutorials will be easy to read, but won't get me far enough.
Hardcore academic papers will be hard to read (at least because reading two-column PDFs on a phone screen sucks) and may go into too much detail.
Also, my task might have some specifics which could render many resources irrelevant or hard to apply.

LLMs, such as ChatGPT, are the missing piece.
We can ask this calculator for words "how would you efficiently display billions of pins on a Leaflet map?" and the conversation which will follow can show us various existing approaches and their names.
This is big!

Education system in my country slowly notices that the internet exists, and this is going to be another blow to its 19th-century-like structure.
The society will now really need to figure out what the schools should be about.
But let's skip this huge topic for now and focus back on the junior devs.

Existence of a tool like ChatGPT means the gap in general overview between graduates and career switchers is closing.
There will be differences in other areas, such as opportunities, contacts, networking, but not in solving difficult tasks.

You know some Python and want to write a program detecting BPM (beats per minute) of songs?
Perhaps other cool stuff with sound waves?
Ask ChatGPT to guide you.
It will tell you [Fourier transforms](https://en.wikipedia.org/wiki/Fourier_transform) exist and what they're about.
Perhaps it can tell you how to use Wolfram Alpha to calculate what you need.
It will tell you how it's relevant to your specific project.
And if you ask well, it can explain all these things to you [like you're five](https://www.howtogeek.com/694298/what-does-eli5-mean-and-how-do-you-use-it/).

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Since ChatGPT launched in Nov&#39;22, <a href="https://twitter.com/StackOverflow?ref_src=twsrc%5Etfw">@StackOverflow</a> traffic dropped 24% from peak, 13% from avg. What other categories of websites - other than technical forums - got affected ? <a href="https://t.co/rBctmGPPEW">pic.twitter.com/rBctmGPPEW</a></p>&mdash; Mohamed ElAdany (@mohadany) <a href="https://twitter.com/mohadany/status/1642544573137158144?ref_src=twsrc%5Etfw">April 2, 2023</a></blockquote>

## Diversity and communication skills preferred

I also think ChatGPT etc. will change what a dev's skillset looks like.
We can already observe companies now prefer people who can work in teams over introvert geniuses.
This transformation is painful, because the previous generations of devs were often solo geeks, and great communication skills or enthusiasm for teamwork were not among the main requirements for the job.
If they're unable to adapt, they are now categorized as _brilliant jerks_ and pushed aside.

Simon Willison [observes](https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/) that for crafting good AI prompts, you need really great communication skills.
Prompting for complex stuff gets difficult quite quickly and one may also need things like linguistics, human psychology, philosophy…
In case of image generation, people who know digital art or art history have a significant advantage.

If devs can't get away with just technical skills today, I think this will only be more true in the future.
The question is, is it now easier to take communicative people who studied art or psychology, and teach them coding, or is it easier to take professional coders and make them more communicative?
I think the former is true and career switchers have a big advantage here.

In [our latest podcast episode](https://junior.guru/podcast/#episode0015) (in Czech), Marián Kameništák also mentions companies could actually start preferring domain knowledge over technical skills.
There are accountants, artists, dentists, biologists, train drivers, bankers, or chemists already switching their careers to tech.
Not only they have unique domain expertise, but also different backgrounds.

We already know that solutions are serving people better if they're made by a diverse crowd of devs.
But diversity is not just about "women in tech", it goes as far as "single parents in tech", "remote mountain dwellers in tech" or "former dentists in tech".
I think in the age of AI-augmented software engineering this will become more and more apparent.

## LLMs are not replacing all devs

Does it make sense to learn coding at all though?
What if AI gets so good that it's able to produce not only _hello world_ React components, but whole apps?
Complex systems?
What if it learns to understand and maintain all the legacy codebases and one day, it makes all software engineers redundant?
Josh Comeau already wrote what I think about this, so let me quote from his article:

> …there is an _enormous_ difference between generating a 50-line HTML document and spitting out a production-ready web application. (…)
>
> Even with 95% accuracy rate, this would be _incredibly_ difficult to debug. It would be like a developer spending _months_ building a huge project, without _ever_ actually trying to run any of the code, until it was 100% finished. This is the stuff of nightmares.
>
> AI isn't magic. It's only as good as its training data. Code _snippets_ are all over the internet, and are often generic. By contrast, every _codebase_ is unique. There are very few large open-source codebases. How's the AI supposed to learn how to build big real-world projects?
>
> We're very quickly reaching the point where non-developers can sit down with a chatbot and crank out a small self-contained project, the sort of thing that folks currently use tools like Webflow to build. And that's awesome!
>
> But I think we're still a _very long way_ from major tech companies letting go of their developer staff and replacing them with prompt engineers. It seems to me like there are several potentially-unsolveable problems that stand in the way of this becoming a reality.
>
> (…) My personal belief is that for the most part, working professionals will find ways to integrate this technology into their workflows, increasing their productivity and value. Certain _tasks_ might be delegated to an AI, but not many _jobs_.
>
> — Josh Comeau, [The End of Front-End Development](https://www.joshwcomeau.com/blog/the-end-of-frontend-development/)

Besides, I think that software engineering is about understanding what people need and translating it to a _very comprehensive and precise specification_.
And that specification is called code.

![Commit Strip]({static}/images/strip-les-specs-cest-du-code-650-finalenglish.jpg)
[A very comprehensive and precise spec](https://www.commitstrip.com/en/2016/08/25/a-very-comprehensive-and-precise-spec/), famous Commit Strip from 2016

Code is the best representation of what should happen when, and it cannot be completely replaced by vaguely formulated prompts.
Yes, code did start as a set of detailed technical instructions for computers, but already since [high-level programming languages](https://en.wikipedia.org/wiki/High-level_programming_language) we're moving up the abstraction ladder and I believe majority of the code written today is closer to describing [business logic](https://en.wikipedia.org/wiki/Business_logic) than to specifying how memory should be managed.
From contract between humans and computers, code gradually becomes contract between humans.

I do believe LLMs can significantly augment our abilities to write the contract, but I don't think the part where we understand what people need, exactly, and translate it to the contract, exactly, can be completely unmanned.
We'll still do the same job we do, just on a higher level of abstraction.

## Devaluation of devs

Let me repeat and point out this part I already quoted:

> We're very quickly reaching the point where non-developers can sit down with a chatbot and crank out a small self-contained project, the sort of thing that folks currently use tools like Webflow to build. And that's awesome!
>
> — Josh Comeau, [The End of Front-End Development](https://www.joshwcomeau.com/blog/the-end-of-frontend-development/)

I see this already happening.
My friend [Jiří Chlebus](https://www.jirichlebus.cz/) is an excellent freelance designer, but his dream is to build his own product.
For years he's been working on an app which disrupts graphic manuals, [Visualbook](https://visualbook.pro/).

He doesn't know how to code, so he was left with learning random bits from the internet, glueing no-code building blocks, getting advice from friends.
ChatGPT has changed everything for him.
He can do stuff he didn't think he'd be able to do.
Translating the app to multiple languages took him fraction of the time, because ChatGPT is able to translate whole HTML chunks.
Dope!

What does this illustrate?
AI not only makes the transition from junior to senior dev faster and easier.
It goes as far as democratizing coding for the masses.
This is good for the progress of humankind, but will have consequences for the devs.
I see two possible scenarios.

## Insatiable demand for devs

In one scenario AI raises supply for devs who are _good enough_ and it balances out the seemingly insatiable demand for devs.
Such end of the scarcity would mean, above all, drop of our high salaries, but also end to the elevated celebrity status of our ocuppation.
This would be good for the society, as developing software just becomes easier and cheaper.

Currently we're in an economic downturn, but I believe that's just a temporary detour caused by current geopolitics.
According to a 2018 poll from the [Czech Statistical Office](https://www.czso.cz/csu/czso/na-trhu-je-nedostatek-ict-odborniku), two thirds of Czech companies said they have issues to fill IT roles.
In 2018, the State of European Tech survey stated that [IT grows 5 times faster than any other segment](https://2018.stateofeuropeantech.com/).
In 2021, it projected that [$100B has been invested to European IT in a single year](https://2021.stateofeuropeantech.com/), 10 times more than when the survey has started in 2015.

Your present personal experience as a junior dev struggling to get invited for an interview might feel different, but the long-term global trend is clear.
Over time, more and more human activity moves to the internet, to computers, to phones.
Everything is, to larger and larger extent, backed by software engineering.

How much would the supply need to raise so that there's enough _good enough_ devs to balance out such demand?
Are we talking about tens of thousands of newcomers to the field?
Perhaps hundreds of thousands?
How long it takes them to decide to get trained as devs and become _good enough_, even with ChatGPT?

## Induced demand for devs

In another scenario, which I think is more likely, there will be [induced demand](https://en.wikipedia.org/wiki/Induced_demand).
If you add one more lane to a congested highway, you may think it's gonna make it less congested.
But as the paradox of induced demand describes, making commuting by car easier, more accesible, and more comfortable like this causes more people to jump into cars and use that new line.
The same way, if cycling paths in your city are [dangerous and sparse](https://mestemnakole.cz/en/prague-cycle-route-system/), nobody uses them.
As soon as you make them easy to use, you suddenly [generate hundreds of cyclists](https://www.theguardian.com/lifeandstyle/2021/mar/12/europe-cycling-post-covid-recovery-plans) who didn't exist previously.

Anyone can make music, and that is awesome.
You can flip a few buckets and play on them like [John Bonham](https://en.wikipedia.org/wiki/John_Bonham).
There are open source tools like [LMMS](https://lmms.io/) which give the [FL Studio](https://www.image-line.com/fl-studio/) experience to masses.
There is YouTube full of lessons and tutorials, making learning instruments easier and more accessible than ever.
Anyone can employ their creativity and make their own music.
Did professional musicians disappear?
No.
Does it augment everyones' abilities and make us all more ambitious?
Yes!

Imagine what it took to be a photographer in the 19th century.
Today everyone has a camera in their phone.
Everyone produces tens, some even hundreds of photos every day.
Did it make the photographer profession go away?
Did employing AI in modern professional cameras make the occupation disappear?
No.
Does it augment everyones' abilities and make us all more ambitious?
Yes!

> Believe it or not, the number of professional photographers has been _increasing_, year over year. The US Bureau of Labor Statistics expects the number of jobs to increase 9% year-over-year for the next decade. For context, the average across all industries is 5%
>
> — Josh Comeau, [The End of Front-End Development](https://www.joshwcomeau.com/blog/the-end-of-frontend-development/)

People can already solve some coding problems on their own.
First WordPress, now Webflow, Wix, Shopify, and all the recent _no-code_ and _low-code_ hype.
And that's good!
Some don't even need that, because for their business it's just enough to have an Instagram profile with a few photos and a phone number.
This didn't make devs redundant.
We moved to more ambitious projects, such as custom development and SaaS applications.

All professionals, whether it is musicians, photographers, or devs, share one important quality:
They know what they're doing, and why.
The ease and accesibility of taking pictures didn't cause wedding photographers go bankrupt, it caused ordinary people go and take pictures of their butt.
Or coffee.
Or dog.

The paradox of induced demand applies to your personal life, too.
Did washing machines, robot vacuums or smartphones make you more relaxed than your ancestors?
No.
It allowed you to be more ambitious.
Your ancestors knew they can fit two activities into their day and wished they could manage to get done five.
You can fit 20 and wish you could manage to get done 50.

Guess what happens with LLMs like ChatGPT?
Let me quote Simon Willison:

> As an experienced developer, ChatGPT (and GitHub Copilot) save me an enormous amount of “figuring things out” time. For everything from writing a for loop in Bash to remembering how to make a cross-domain CORS request in JavaScript—I don’t need to even look things up any more, I can just prompt it and get the right answer 80% of the time.
>
> This doesn’t just make me more productive: it lowers my bar for when a project is worth investing time in at all.
>
> In the past I’ve had plenty of ideas for projects which I’ve ruled out because they would take a day—or days—of work to get to a point where they’re useful. I have enough other stuff to build already!
>
> But if ChatGPT can drop that down to an hour or less, those projects can suddenly become viable.
>
> — Simon Willison, [AI-enhanced development makes me more ambitious with my projects](https://simonwillison.net/2023/Mar/27/ai-enhanced-development/)

The fact that AI-augmented Simon is as capable as a team of devs doesn't lead to devs losing jobs.
It leads to Simon doing more stuff which couldn't exist before.
If building software gets easier and more accessible, it will only make us all more ambitious.

## More indie hackers

There will definitely be a shakeup on the job market though.
If a company needed 100 people to do something and now 10 are enough, this will have impact.
In smart companies, the remaining 90 people will be re-assigned to work on ambitious projects the company didn't think could be doing before.
In some companies, the 90 will lose their jobs.

On the other hand, after layoff those people can now go and do stuff they probably wouldn't even dream about before.
[The 4-Hour Workweek](https://en.wikipedia.org/wiki/The_4-Hour_Workweek) by Tim Ferriss tells people to check email once per day and outsource small daily tasks to _virtual assistants_.
I guess this will now become an option more viable than ever, at least until the majority catches up with all the new tech.

But let's say you want to add some value to this world.
New tools for content creators, such as YouTube or Substack, have augmented peoples' abilities to the point that newsletter author, podcast host, beauty influencer, YouTube videos producer, or Twitch streamer seem like viable careers.
The same will happen with startups.

[Pieter Levels](https://levels.io/) became famous for [showing people](https://readmake.com/) that with tools like [Stripe](https://stripe.com/), it's possible to build a whole startup product as a single person.
There are already [communities of indie hackers](https://www.indiehackers.com/) and individual makers whose dream is to have their own scaling business.
Not a freelance business, where you sell your time for bucks, but scaling business, which allows you to live an independent life, whatever that word means.

If 100 employees can be replaced by 10 AI-augmented employees, then what about a single AI-augmented enterpreneur?
What if one bootstrapped founder becomes as capable in delivering a product as whole Silicon Valley teams?

The same way YouTube disrupted TV production and now everyone can have their own TV, AI could disrupt Silicon Valley.
If capital or experienced people won't be so crucial to deliver a useful product, can we see more apps coming e.g. from [Namibia]({filename}2021-06-17_jessica-upani-about-python-events-in-namibia-you-have-to-be-pure-in-terms-of-your-why.md) or [Ghana](https://blog.pythonghana.org/)?

## Keep your FOMO at bay

Now you may think that if you are not on top of all the announcements, you're already missing out.
Let me re-assure you that the majority of inhabitants of this world do not use ChatGPT yet.

Next time you commute in a tram, look around and think about how many of the people you see there has already their own elaborate ChatGPT or Stable Diffusion promptbook.
This can have serious consequences, such as big societal division between those who have access to AI and those who don't.
Remember how during the pandemic [we learned](https://cc.cz/sbirka-pocitacu-od-cesko-digital-pomohla-2-800-rodinam-s-online-vyukou-pod-kridla-ji-nove-bere-clovek-v-tisni/) that many families in Czechia don't have even good access to computers?
Even though I see some opportunities for AI-induced [social mobility](https://en.wikipedia.org/wiki/Social_mobility), I'm afraid it'll end up like always.
Rich and privileged will become even more rich and more privileged.

So you can be anxious about that.
But forget the _fear of missing out_!
Just the fact you're reading this article probably means you're among the top 0.1% of early adopters.
If you asked ChatGPT more than five times, you're probably among the top 0.001%.

Look at this [weekly report of new stuff happening around AI](https://www.reddit.com/r/ChatGPT/comments/12o29gl/gpt4_week_4_the_rise_of_agents_and_the_beginning/).
Not even people whose job is to do AI are able to keep up.
We're whitnessing a mass exploration of technology, which is easy to use and accessible to basically anyone, including children.
However, most of the stuff is:

-   Selling snake oil.
-   A demo which breaks with inputs just a bit more complex than what they have on a screencast.
-   Not at all that easy as it looks like.

Most of the stuff also isn't a product.
Not even the ChatGPT interface is a real product, officially it is just a [research preview](https://openai.com/blog/chatgpt).
I've tried playing around with Stable Diffusion on my own machine and I was quite surprised how hard it is to produce something at least half appealing as all the images I could see all over the internet.
It's possible, but nowhere near to simple or easy.
The prompting is convoluted, then you have all the different models, techniques, etc.
Stable Diffusion is free, it's definitely powerful, but it's a crude resource.

I feel like if I learn prompting it now, I'm not learning how to drive a car to transport myself on long distances, I'm learning how to build an engine.
To have our abilities effectively augmented, we need real products.
If you wait for the products, you may not be the winner of the gold rush to create the products, but you'll have much easier time to actually use the new superpowers for something else.

Every day I think about ways how to integrate AI to my product and my workflow.
If I didn't think for so long and instead started working on it already, I'd have it done by now.
At the same time, with every new announcement every week, I feel like having the job done is easier and easier.
I saved myself a lot of unnecessary work!
I might not be the first person integrating AI to an existing product.
However, I think that if I can do it in 2023, I'll be still among the first 5 %.
And it's only going to be easier over time.

## Checking my bias

That's all folks!
Thanks for reading.
Now the only thing left is:
How can I be so sure about all this?
Well, I'm not sure at all!
On the chart below, I think I'm somewehre between the utopianist and the enterpreneur.

![r/ChatGPT classes]({static}/images/ph8h1yjb6aua1.png)
[r/ChatGPT classes](https://www.reddit.com/r/ChatGPT/comments/12ohyf8/choose_your_class_or_add_one/), Reddit

I'm an indie hacker in the business of getting more people to learn coding.
Maybe I see only what I want to see.
Maybe I've spent several days writing this just to come up with a reasoning why AI won't render useless me and everything I've been doing for decades.

This blog post is full of various predictions, so it's doomed to be outdated in about two weeks, if I'm lucky.
That's also why I decided to put all my thoughts on the topic in a single post.
If I was to split them, the some of the individual posts could become old before I manage to publish them and the whole thing wouldn't stick together anymore.
This way I can at least say this is what was my wishful thinking about AI in the middle of April 2023.
